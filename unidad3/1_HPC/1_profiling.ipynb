{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualización en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python y  Rendimiento | Parte 1\n",
    "\n",
    "Python es un lenguaje interpretado de alto nivel que es muy conveniente para prototipar y hacer análisis \n",
    "exploratorio\n",
    "\n",
    "Esto tiene un costo: Menor **rendimiento** a igual **complejidad** en comparación a lenguajes compilados de bajo nivel\n",
    "\n",
    "Podemos ser más específicos y hablar de **eficiencia**:\n",
    "\n",
    "> Temporal: Tiempo para completar una tarea (tiempo en la CPU)\n",
    "\n",
    "> Espacial: Utilización de espacio (memoria RAM, disco)\n",
    "\n",
    "Ambos son factores críticos en algunas aplicaciones (big-data)\n",
    "\n",
    "Existe entonces una necesidad por mejorar el rendimiento de nuestro código\n",
    "\n",
    "> A esto lo llamamos **Optimización** de código\n",
    "\n",
    "En la siguiente clase veremos distintas formas de **optimizar** código escrito en Python\n",
    "\n",
    "Sin embargo antes de optimizar es necesario diagnosticar e identificar los sectores críticos (cuellos de botella) de nuestro programa\n",
    "\n",
    "> Esto lo llamamos *Profiling* de código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *Profiling*\n",
    "\n",
    "Se refiere a medir los \n",
    "\n",
    "1. Tiempos de ejecución (total, por función, por linea)\n",
    "1. Uso de recursos (memoria, cpu, disco)\n",
    "\n",
    "de una rutina con el fin de encontrar aquellas secciones más lentas e ineficientes (sectores críticos)\n",
    "\n",
    "Luego de identificarlas podemos reescribirlas u optimizarlas\n",
    "\n",
    "En esta clase veremos como hacer un *profiling* de nuestro código en Python usando el ambiente *Jupyter* y las magias de *IPython*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Set de Julia\n",
    "\n",
    "El [set de Julia](https://en.wikipedia.org/wiki/Julia_set) es un fractal asociado a la función\n",
    "\n",
    "$$\n",
    "f(z) = z^2 + c,\n",
    "$$\n",
    "donde $c \\in \\mathbb{C}$\n",
    "\n",
    "El script [fractal.py](./fractal.py) tiene una implementación del set de Julia usando Python puro (sin librerias)\n",
    "\n",
    "Si ejecutamos la función `make_fractal.py` con una resolución de 500 pixeles y 50 iteraciones el resultado es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractal import make_fractal, evaluate_z\n",
    "fractal_image = make_fractal(N=500, maxiters=50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4), tight_layout=True)\n",
    "ax.imshow(fractal_image, aspect='equal', cmap=plt.cm.viridis, origin='lower')\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos partial para fijar los parámetros de `make_fractal`\n",
    "\n",
    "A continuación haremos un *profiling* de `slow_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_function = partial(make_fractal, N=500, maxiters=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiempo de ejecución con magias de IPython\n",
    "\n",
    "Podemos medir el tiempo total de un bloque de ejecución completo con la magia `%%time`\n",
    "\n",
    "¿Cuánto demora en calcularse el set de julia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "result = slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi computador (Core i5-4200U, 1.6 Ghz) demora 1.88s\n",
    "\n",
    "¿Cuánto demora en el tuyo? ¿Cómo se compara tu CPU con el mio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos medir el tiempo de una linea en particular con la magia `%time`\n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time result1 = slow_function()\n",
    "%time result2 = slow_function()\n",
    "%time result3 = slow_function()\n",
    "%time result4 = slow_function()\n",
    "# Son los resultados iguales?\n",
    "np.allclose(result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de ejecutar el mismo código y obtener el mismo resultado los tiempos de cómputo son ligeramente distintos ¿Por qué?\n",
    "\n",
    "> Cada vez que ejecutamos un código alteramos el estado de nuestro sistema (cache, memoria)\n",
    "\n",
    "La magia `%timeit -rX -nY` ejecuta nuestro código X veces y retorna el tiempo promedio y la desviación estándar. Por cada ejecución se guarda el mejor tiempo de Y repeticiones\n",
    "\n",
    "El tiempo para 10 repeticiones del set de julia es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r10 -n1 result = slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta magia se basa en el módulo de Python [timeit](https://docs.python.org/3/library/timeit.html)\n",
    "\n",
    "**OJO:** Los tiempos de `timeit` suelen ser menores a los de `time`. Es porque `timeit` omite las tareas de *garbage collection*\n",
    "\n",
    "Podemos activar *gc* usando el módulo de forma directa:\n",
    "\n",
    "    import timeit\n",
    "    timeit.timeit(slow_function, 'gc.enable()', number=10)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Midiendo el tiempo de cada función con cProfile\n",
    "\n",
    "El módulo de Python [cProfile](https://docs.python.org/3/library/profile.html) mide la cantidad de llamadas y el tiempo de cada función ejecutada por nuestra rutina\n",
    "\n",
    "El resultado es una tabla con las siguientes filas\n",
    "\n",
    "- ncalls: Número de veces que se llama la función\n",
    "- tottime: Tiempo total en dicha función (sin contar subfunciones)\n",
    "- percall: ttime/ncalls\n",
    "- cumtime: Tiempo total en dicha función y sus subfunciones (tiempo de función recursiva)\n",
    "- percall: cumtime/ncalls\n",
    "\n",
    "La magia de IPython `%prun` nos da una forma conveniente para usar este módulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la tabla vemos que \n",
    "- La función con mayor tiempo total es `evaluate_z` que está en la linea 1 de fractal.py\n",
    "- `evaluate_z()` se llama 500.000 veces\n",
    "\n",
    "En general el tiempo total es mayor que el que medimos con `time` y `timeit`: Esto corresponde al overhead de `prun`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opciones importantes de `prun`\n",
    "- `-s` para que el resultado quede ordenado según una fila en particular \n",
    "- `-l` si queremos especificar la cantidad de líneas a mostrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun -s cumtime slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos usar `%%prun` para hacer *profiling* de un bloque completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -l 5 -s cumtime \n",
    "\n",
    "data = np.random.randn(100000)\n",
    "hist, edges = np.histogram(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y si no contamos con el ambiente IPython podemos usar cProfile directamente sobre un script de Python con\n",
    "\n",
    "        python -m cProfile -o tabla.prof script.py\n",
    "        \n",
    "Donde el resultado queda grabado en el archivo tabla.prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizando con snakeviz\n",
    "\n",
    "Podemos generar una visualización de los resultados de `cProfile` en nuestro navegador usando [`SnakeViz`](https://jiffyclub.github.io/snakeviz/)\n",
    "\n",
    "Primero lo instalamos con [conda](https://anaconda.org/conda-forge/snakeviz) o con\n",
    "\n",
    "    pip3 install snakeviz\n",
    "    \n",
    "Esto creará un ejecutable snakeviz en `/usr/bin`\n",
    "\n",
    "Luego cargamos la extensión para jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora podemos usar las magias `%snakeviz` para una rutina y `%%snakeviz` para un bloque completo\n",
    "\n",
    "La opción `-t` carga el gráfico en una pestaña de navegador nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%snakeviz -t slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta herramiento puede mejorar considerablemente el estudio de nuestro código cuando se tiene una gran cantidad de funciones en distintas jerarquías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Midiendo el tiempo de cada linea\n",
    "\n",
    "A veces puede ser más informativo medir el tiempo linea a linea en lugar de función a función\n",
    "\n",
    "Podemos lograr esto último usando la extensión [`line_profiler`](https://github.com/rkern/line_profiler). \n",
    "\n",
    "Luego de instalar y habilitarla tendremos a disposición la magia `%lprun` que funciona de forma similar a `prun`\n",
    "\n",
    "***\n",
    "Se recomienda instalar con conda: https://anaconda.org/anaconda/line_profiler\n",
    "\n",
    "Si no usas conda puedes instalar manualmente con\n",
    "\n",
    "    git clone https://github.com/rkern/line_profiler.git\n",
    "    find line_profiler -name '*.pyx' -exec cython {} \\;\n",
    "    cd line_profiler && pip3 install . --user \n",
    "    \n",
    "La instalación con PIP no funciona de momento (ver repositorio de line_profiler)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La magia requiere que se especifique un método/función dentro de la rutina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f make_fractal slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casi el 90% del tiempo se ocupa en la linea 20 , la función `evaluate_z`\n",
    "\n",
    "Podemos hacer run profiling de dicha función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f evaluate_z slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de memoria con magias de IPython\n",
    "\n",
    "Podemos descargar y habilitar la extensión `memory_profiler` para medir la cantidad de memoria usada por nuestra rutina\n",
    "\n",
    "    pip3 install memory_profiler --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar `%memit` para medir la memoria total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y `%mprun` para medir el uso de memoria linea por linea\n",
    "\n",
    "**OJO:** `mprun` requiere que la función esté escrita en un archivo `.py` (en este caso está en fractal.py)\n",
    "\n",
    "    %mprun -f make_fractal make_fractal(N=50, maxiter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de memoria con `trace`\n",
    "\n",
    "Próxima iteración\n",
    "\n",
    "Brett Slatkin, Effective Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
